{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-15T08:27:22.218724900Z",
     "start_time": "2026-01-15T08:27:22.043360800Z"
    }
   },
   "source": [
    "# =============================================================================\n",
    "# SETUP AND IMPORTS\n",
    "# =============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "# Add src directory to Python path\n",
    "sys.path.insert(0, os.path.abspath('../src'))\n",
    "\n",
    "# Data processing\n",
    "from data_loader import load_and_preprocess\n",
    "\n",
    "# Model training\n",
    "from model_trainer import train_final_model, train_all_baseline_models\n",
    "\n",
    "# Model evaluation\n",
    "from model_evaluator import full_evaluation_report, compare_models\n",
    "\n",
    "# Visualizations\n",
    "from visualizations import (\n",
    "    plot_model_comparison,\n",
    "    plot_predictions,\n",
    "    plot_residuals,\n",
    "    plot_feature_importance,\n",
    "    plot_cv_scores,\n",
    "    create_summary_dashboard\n",
    ")\n",
    "\n",
    "# Confirmation\n",
    "print(\"=\" * 60)\n",
    "print(\"‚úì All modules imported successfully\")\n",
    "print(\"=\" * 60)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "‚úì All modules imported successfully\n",
      "============================================================\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T08:27:24.693660700Z",
     "start_time": "2026-01-15T08:27:24.644652100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### Day 8: Elastic Net + Interaction Feature\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append('../src')\n",
    "from data_loader import load_and_preprocess\n",
    "from linear_regression import ElasticNetScratch, LinearRegressionScratch\n",
    "import numpy as np\n",
    "\n",
    "data = load_and_preprocess()\n",
    "print(\"‚úì Data loaded\")\n",
    "\n",
    "#### Part 1: Test Elastic Net with Different l1_ratio\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ELASTIC NET: L1/L2 RATIO COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "l1_ratios = [0.0, 0.25, 0.5, 0.75, 1.0]  # 0=Ridge, 1=Lasso\n",
    "results_elastic = []\n",
    "\n",
    "for l1_ratio in l1_ratios:\n",
    "    model = ElasticNetScratch(alpha=0.1, l1_ratio=l1_ratio, n_iterations=1000)\n",
    "    model.fit(data['X_train_scaled'], data['y_train'])\n",
    "\n",
    "    val_r2 = model.score(data['X_val_scaled'], data['y_val'])\n",
    "    n_nonzero = np.sum(np.abs(model.weights) > 1e-5)\n",
    "\n",
    "    results_elastic.append({\n",
    "        'l1_ratio': l1_ratio,\n",
    "        'val_r2': val_r2,\n",
    "        'n_features': n_nonzero\n",
    "    })\n",
    "\n",
    "    model_type = \"Ridge\" if l1_ratio == 0 else (\"Lasso\" if l1_ratio == 1 else \"Elastic Net\")\n",
    "    print(f\"\\n{model_type} (l1_ratio={l1_ratio}):\")\n",
    "    print(f\"  Val R¬≤: {val_r2:.4f}, Active features: {n_nonzero}/6\")"
   ],
   "id": "c70ddbda14cea750",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATA PREPROCESSING PIPELINE\n",
      "============================================================\n",
      "‚úì Loaded 1460 samples, 81 features\n",
      "‚úì Selected 6 features\n",
      "  Features: ['OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', '1stFlrSF', 'YearBuilt']\n",
      "‚úì Removed 2 outliers: 1460 ‚Üí 1458 samples\n",
      "‚úì Split complete:\n",
      "  Train: 1093 (75.0%)\n",
      "  Val:   219 (15.0%)\n",
      "  Test:  146 (10.0%)\n",
      "‚úì Features standardized (mean=0, std=1)\n",
      "  Train mean: [-0. -0.  0. -0.  0. -0.]\n",
      "  Train std:  [1. 1. 1. 1. 1. 1.]\n",
      "\n",
      "‚úì Preprocessing complete!\n",
      "‚úì Data loaded\n",
      "============================================================\n",
      "ELASTIC NET: L1/L2 RATIO COMPARISON\n",
      "============================================================\n",
      "‚úì Converged at iteration 13\n",
      "‚úì Elastic Net trained (alpha=0.1, l1_ratio=0.0)\n",
      "\n",
      "Ridge (l1_ratio=0.0):\n",
      "  Val R¬≤: 0.8479, Active features: 6/6\n",
      "‚úì Converged at iteration 13\n",
      "‚úì Elastic Net trained (alpha=0.1, l1_ratio=0.25)\n",
      "\n",
      "Elastic Net (l1_ratio=0.25):\n",
      "  Val R¬≤: 0.8479, Active features: 6/6\n",
      "‚úì Converged at iteration 13\n",
      "‚úì Elastic Net trained (alpha=0.1, l1_ratio=0.5)\n",
      "\n",
      "Elastic Net (l1_ratio=0.5):\n",
      "  Val R¬≤: 0.8479, Active features: 6/6\n",
      "‚úì Converged at iteration 13\n",
      "‚úì Elastic Net trained (alpha=0.1, l1_ratio=0.75)\n",
      "\n",
      "Elastic Net (l1_ratio=0.75):\n",
      "  Val R¬≤: 0.8479, Active features: 6/6\n",
      "‚úì Converged at iteration 13\n",
      "‚úì Elastic Net trained (alpha=0.1, l1_ratio=1.0)\n",
      "\n",
      "Lasso (l1_ratio=1.0):\n",
      "  Val R¬≤: 0.8478, Active features: 6/6\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T08:27:29.529504700Z",
     "start_time": "2026-01-15T08:27:29.443116900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#### Part 2: Elastic Net with FullBath (Multicollinearity Test)\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ELASTIC NET vs FEATURE REMOVAL (FullBath)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Load data WITH FullBath\n",
    "data_with_bath = load_and_preprocess(\n",
    "    filepath='../data/train.csv',\n",
    "    remove_fullbath=False,  # Keep FullBath\n",
    "    remove_outliers_flag=True\n",
    ")\n",
    "\n",
    "print(f\"\\nFeatures (7): {data_with_bath['feature_names']}\")\n",
    "\n",
    "# Test different l1_ratios with FullBath included\n",
    "print(\"\\nElastic Net with FullBath (7 features):\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "elastic_results = []\n",
    "\n",
    "for l1_ratio in [0.0, 0.5, 1.0]:\n",
    "    for alpha in [0.001, 0.01, 0.1, 1.0]:\n",
    "        model = ElasticNetScratch(alpha=alpha, l1_ratio=l1_ratio, n_iterations=1000)\n",
    "        model.fit(data_with_bath['X_train_scaled'], data_with_bath['y_train'])\n",
    "\n",
    "        val_r2 = model.score(data_with_bath['X_val_scaled'], data_with_bath['y_val'])\n",
    "\n",
    "        # Check FullBath weight (index 5)\n",
    "        fullbath_weight = model.weights[5]\n",
    "        n_nonzero = np.sum(np.abs(model.weights) > 1e-5)\n",
    "\n",
    "        elastic_results.append({\n",
    "            'alpha': alpha,\n",
    "            'l1_ratio': l1_ratio,\n",
    "            'val_r2': val_r2,\n",
    "            'fullbath_weight': fullbath_weight,\n",
    "            'n_features': n_nonzero\n",
    "        })\n",
    "\n",
    "        model_type = \"Ridge\" if l1_ratio == 0 else (\"Lasso\" if l1_ratio == 1 else \"Elastic\")\n",
    "        print(\n",
    "            f\"{model_type} (Œ±={alpha:5.3f}, l1={l1_ratio}): R¬≤={val_r2:.4f}, FullBath={fullbath_weight:>7.4f}, Features={n_nonzero}/7\")\n",
    "\n",
    "# Compare best Elastic Net vs Feature Removal\n",
    "df_elastic = pd.DataFrame(elastic_results)\n",
    "best_elastic = df_elastic.loc[df_elastic['val_r2'].idxmax()]\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"COMPARISON:\")\n",
    "print(f\"{'=' * 60}\")\n",
    "\n",
    "print(f\"\\nApproach 1: Remove FullBath (6 features)\")\n",
    "print(f\"  Val R¬≤: {data['X_val_scaled'].shape} ‚Üí Need to retrain\")\n",
    "\n",
    "# Quick train linear without FullBath\n",
    "model_no_bath = LinearRegressionScratch(learning_rate=0.01, n_iterations=1000)\n",
    "# Suppress output\n",
    "import io, sys\n",
    "\n",
    "old_stdout = sys.stdout\n",
    "sys.stdout = io.StringIO()\n",
    "model_no_bath.fit(data['X_train_scaled'], data['y_train'])\n",
    "sys.stdout = old_stdout\n",
    "\n",
    "val_r2_no_bath = model_no_bath.score(data['X_val_scaled'], data['y_val'])\n",
    "\n",
    "print(f\"  Val R¬≤: {val_r2_no_bath:.4f}\")\n",
    "print(f\"  FullBath weight: N/A (removed)\")\n",
    "\n",
    "print(f\"\\nApproach 2: Elastic Net with FullBath (7 features)\")\n",
    "print(f\"  Best config: alpha={best_elastic['alpha']}, l1_ratio={best_elastic['l1_ratio']}\")\n",
    "print(f\"  Val R¬≤: {best_elastic['val_r2']:.4f}\")\n",
    "print(f\"  FullBath weight: {best_elastic['fullbath_weight']:.4f}\")\n",
    "print(f\"  Active features: {int(best_elastic['n_features'])}/7\")\n",
    "\n",
    "if best_elastic['val_r2'] > val_r2_no_bath:\n",
    "    print(f\"\\n‚úì Elastic Net better by {best_elastic['val_r2'] - val_r2_no_bath:.4f}\")\n",
    "else:\n",
    "    print(f\"\\n‚úó Feature removal still better by {val_r2_no_bath - best_elastic['val_r2']:.4f}\")"
   ],
   "id": "1dc03c2e00a2237f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ELASTIC NET vs FEATURE REMOVAL (FullBath)\n",
      "============================================================\n",
      "============================================================\n",
      "DATA PREPROCESSING PIPELINE\n",
      "============================================================\n",
      "‚úì Loaded 1460 samples, 81 features\n",
      "‚úì Selected 7 features\n",
      "  Features: ['OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', '1stFlrSF', 'FullBath', 'YearBuilt']\n",
      "‚úì Removed 2 outliers: 1460 ‚Üí 1458 samples\n",
      "‚úì Split complete:\n",
      "  Train: 1093 (75.0%)\n",
      "  Val:   219 (15.0%)\n",
      "  Test:  146 (10.0%)\n",
      "‚úì Features standardized (mean=0, std=1)\n",
      "  Train mean: [-0. -0.  0. -0.  0.  0. -0.]\n",
      "  Train std:  [1. 1. 1. 1. 1. 1. 1.]\n",
      "\n",
      "‚úì Preprocessing complete!\n",
      "\n",
      "Features (7): ['OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', '1stFlrSF', 'FullBath', 'YearBuilt']\n",
      "\n",
      "Elastic Net with FullBath (7 features):\n",
      "------------------------------------------------------------\n",
      "‚úì Converged at iteration 18\n",
      "‚úì Elastic Net trained (alpha=0.001, l1_ratio=0.0)\n",
      "Ridge (Œ±=0.001, l1=0.0): R¬≤=0.8474, FullBath=-0.0220, Features=7/7\n",
      "‚úì Converged at iteration 18\n",
      "‚úì Elastic Net trained (alpha=0.01, l1_ratio=0.0)\n",
      "Ridge (Œ±=0.010, l1=0.0): R¬≤=0.8474, FullBath=-0.0220, Features=7/7\n",
      "‚úì Converged at iteration 18\n",
      "‚úì Elastic Net trained (alpha=0.1, l1_ratio=0.0)\n",
      "Ridge (Œ±=0.100, l1=0.0): R¬≤=0.8474, FullBath=-0.0220, Features=7/7\n",
      "‚úì Converged at iteration 17\n",
      "‚úì Elastic Net trained (alpha=1.0, l1_ratio=0.0)\n",
      "Ridge (Œ±=1.000, l1=0.0): R¬≤=0.8474, FullBath=-0.0218, Features=7/7\n",
      "‚úì Converged at iteration 18\n",
      "‚úì Elastic Net trained (alpha=0.001, l1_ratio=0.5)\n",
      "Elastic (Œ±=0.001, l1=0.5): R¬≤=0.8474, FullBath=-0.0220, Features=7/7\n",
      "‚úì Converged at iteration 18\n",
      "‚úì Elastic Net trained (alpha=0.01, l1_ratio=0.5)\n",
      "Elastic (Œ±=0.010, l1=0.5): R¬≤=0.8474, FullBath=-0.0220, Features=7/7\n",
      "‚úì Converged at iteration 18\n",
      "‚úì Elastic Net trained (alpha=0.1, l1_ratio=0.5)\n",
      "Elastic (Œ±=0.100, l1=0.5): R¬≤=0.8474, FullBath=-0.0218, Features=7/7\n",
      "‚úì Converged at iteration 17\n",
      "‚úì Elastic Net trained (alpha=1.0, l1_ratio=0.5)\n",
      "Elastic (Œ±=1.000, l1=0.5): R¬≤=0.8473, FullBath=-0.0201, Features=7/7\n",
      "‚úì Converged at iteration 18\n",
      "‚úì Elastic Net trained (alpha=0.001, l1_ratio=1.0)\n",
      "Lasso (Œ±=0.001, l1=1.0): R¬≤=0.8474, FullBath=-0.0220, Features=7/7\n",
      "‚úì Converged at iteration 18\n",
      "‚úì Elastic Net trained (alpha=0.01, l1_ratio=1.0)\n",
      "Lasso (Œ±=0.010, l1=1.0): R¬≤=0.8474, FullBath=-0.0220, Features=7/7\n",
      "‚úì Converged at iteration 18\n",
      "‚úì Elastic Net trained (alpha=0.1, l1_ratio=1.0)\n",
      "Lasso (Œ±=0.100, l1=1.0): R¬≤=0.8474, FullBath=-0.0216, Features=7/7\n",
      "‚úì Converged at iteration 18\n",
      "‚úì Elastic Net trained (alpha=1.0, l1_ratio=1.0)\n",
      "Lasso (Œ±=1.000, l1=1.0): R¬≤=0.8472, FullBath=-0.0184, Features=7/7\n",
      "\n",
      "============================================================\n",
      "COMPARISON:\n",
      "============================================================\n",
      "\n",
      "Approach 1: Remove FullBath (6 features)\n",
      "  Val R¬≤: (219, 6) ‚Üí Need to retrain\n",
      "  Val R¬≤: 0.8486\n",
      "  FullBath weight: N/A (removed)\n",
      "\n",
      "Approach 2: Elastic Net with FullBath (7 features)\n",
      "  Best config: alpha=1.0, l1_ratio=0.0\n",
      "  Val R¬≤: 0.8474\n",
      "  FullBath weight: -0.0218\n",
      "  Active features: 7/7\n",
      "\n",
      "‚úó Feature removal still better by 0.0012\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T08:27:40.944973800Z",
     "start_time": "2026-01-15T08:27:36.474862Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "# 1. ADD SRC TO PATH (Critical for finding your modules)\n",
    "if '../src' not in sys.path:\n",
    "    sys.path.append('../src')\n",
    "\n",
    "# 2. IMPORTS FROM YOUR MODULES\n",
    "from data_loader import load_raw_data, select_features, split_data, standardize_features\n",
    "from feature_engineering import engineer_features\n",
    "from linear_regression import ElasticNetScratch\n",
    "\n",
    "# 3. SETUP: Load & Engineer Features\n",
    "print(\"=\" * 60)\n",
    "print(\"DAY 8: ELASTIC NET on 15 ENGINEERED FEATURES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Load base data (KEEP FullBath this time, let Elastic Net decide)\n",
    "df_raw = load_raw_data()\n",
    "X_base, y = select_features(df_raw, remove_fullbath=False)\n",
    "\n",
    "# Generate the 15 Engineered Features\n",
    "print(\"\\n... Engineering Features ...\")\n",
    "X_eng = engineer_features(X_base)\n",
    "\n",
    "# Manually define names to avoid ImportError if get_feature_names isn't in your file\n",
    "feature_names_eng = [\n",
    "    'OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', '1stFlrSF', 'FullBath', 'YearBuilt', # Base (7)\n",
    "    'Quality_Size', 'Age_Quality', 'Bath_Density', 'Garage_Ratio', 'Basement_Ratio', 'Total_Space', 'House_Age', 'Is_New' # Eng (8)\n",
    "]\n",
    "\n",
    "print(f\"‚úì Input Shape: {X_eng.shape} (15 Features)\")\n",
    "\n",
    "# Split & Scale\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = split_data(X_eng, y)\n",
    "X_train_scaled, X_val_scaled, X_test_scaled, _, _ = standardize_features(\n",
    "    X_train, X_val, X_test\n",
    ")\n",
    "\n",
    "# 4. THE BATTLE: Grid Search\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"STARTING GRID SEARCH\")\n",
    "print(f\"{'=' * 60}\")\n",
    "\n",
    "results = []\n",
    "best_val_r2 = -np.inf\n",
    "best_model = None\n",
    "best_params = {}\n",
    "\n",
    "# We check aggressive alphas because we have MANY redundant features\n",
    "alphas = [0.01, 0.05, 0.1, 0.5, 1.0]\n",
    "l1_ratios = [0.1, 0.5, 0.7, 0.9, 1.0] # 1.0 is pure Lasso (Kill mode)\n",
    "\n",
    "for l1 in l1_ratios:\n",
    "    print(f\"\\n--- Testing l1_ratio = {l1} ---\")\n",
    "    for alpha in alphas:\n",
    "        # Train Model\n",
    "        model = ElasticNetScratch(alpha=alpha, l1_ratio=l1, n_iterations=1500)\n",
    "\n",
    "        # Suppress the \"Converged\" print to keep output clean\n",
    "        old_stdout = sys.stdout\n",
    "        sys.stdout = io.StringIO()\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        sys.stdout = old_stdout\n",
    "\n",
    "        # Evaluate\n",
    "        val_r2 = model.score(X_val_scaled, y_val)\n",
    "\n",
    "        # Count survivors (non-zero weights)\n",
    "        # We use a small threshold (1e-4) to treat tiny weights as zero\n",
    "        survivors = np.sum(np.abs(model.weights) > 1e-4)\n",
    "\n",
    "        print(f\"  Œ±={alpha:<5}: Val R¬≤={val_r2:.4f} | Survivors: {survivors}/15\")\n",
    "\n",
    "        results.append({\n",
    "            'alpha': alpha,\n",
    "            'l1_ratio': l1,\n",
    "            'val_r2': val_r2,\n",
    "            'survivors': survivors,\n",
    "            'weights': model.weights\n",
    "        })\n",
    "\n",
    "        if val_r2 > best_val_r2:\n",
    "            best_val_r2 = val_r2\n",
    "            best_model = model\n",
    "            best_params = {'alpha': alpha, 'l1_ratio': l1}\n",
    "\n",
    "# 5. THE WINNER: Feature Analysis\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"THE SURVIVORS (Best Model Weights)\")\n",
    "print(f\"{'=' * 60}\")\n",
    "print(f\"Best Configuration: Alpha={best_params['alpha']}, L1_Ratio={best_params['l1_ratio']}\")\n",
    "print(f\"Best Val R¬≤: {best_val_r2:.4f}\")\n",
    "\n",
    "# Create a clean sorted DataFrame of weights\n",
    "df_weights = pd.DataFrame({\n",
    "    'Feature': feature_names_eng,\n",
    "    'Weight': best_model.weights,\n",
    "    'Abs_Weight': np.abs(best_model.weights)\n",
    "})\n",
    "\n",
    "# Sort by absolute importance\n",
    "df_weights = df_weights.sort_values('Abs_Weight', ascending=False)\n",
    "\n",
    "print(\"\\nRanked Feature Importance:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"{'Feature':<20} | {'Weight':>10} | {'Status'}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for _, row in df_weights.iterrows():\n",
    "    status = \"DEAD\" if row['Abs_Weight'] < 1e-4 else \"ALIVE\"\n",
    "    print(f\"{row['Feature']:<20} | {row['Weight']:>10.4f} | {status}\")\n",
    "\n",
    "# 6. FINAL VERDICT: Engineering vs Base\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"FINAL VERDICT\")\n",
    "print(f\"{'=' * 60}\")\n",
    "\n",
    "# Hardcoded base score from your previous best run (Manual Removal)\n",
    "base_score = 0.8486\n",
    "\n",
    "if best_val_r2 > base_score:\n",
    "    diff = best_val_r2 - base_score\n",
    "    print(f\"WINNER: ENGINEERED FEATURES (+{diff:.4f})\")\n",
    "    print(\"Elastic Net successfully combined the new features!\")\n",
    "else:\n",
    "    diff = base_score - best_val_r2\n",
    "    print(f\"WINNER: SIMPLE BASELINE (Better by {diff:.4f})\")\n",
    "    print(\"Interpretation: The new features added more noise than signal.\")\n",
    "    print(\"Recommendation: Stick to the 6 Base Features for the final model.\")"
   ],
   "id": "2da00c71e69f166f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DAY 8: ELASTIC NET on 15 ENGINEERED FEATURES\n",
      "============================================================\n",
      "‚úì Loaded 1460 samples, 81 features\n",
      "‚úì Selected 7 features\n",
      "  Features: ['OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', '1stFlrSF', 'FullBath', 'YearBuilt']\n",
      "\n",
      "... Engineering Features ...\n",
      "‚úì Input Shape: (1460, 15) (15 Features)\n",
      "‚úì Split complete:\n",
      "  Train: 1095 (75.0%)\n",
      "  Val:   219 (15.0%)\n",
      "  Test:  146 (10.0%)\n",
      "‚úì Features standardized (mean=0, std=1)\n",
      "  Train mean: [ 0.  0. -0.  0. -0. -0.  0. -0. -0.  0.  0. -0. -0. -0. -0.]\n",
      "  Train std:  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "\n",
      "============================================================\n",
      "STARTING GRID SEARCH\n",
      "============================================================\n",
      "\n",
      "--- Testing l1_ratio = 0.1 ---\n",
      "  Œ±=0.01 : Val R¬≤=0.8270 | Survivors: 15/15\n",
      "  Œ±=0.05 : Val R¬≤=0.8270 | Survivors: 15/15\n",
      "  Œ±=0.1  : Val R¬≤=0.8269 | Survivors: 15/15\n",
      "  Œ±=0.5  : Val R¬≤=0.8268 | Survivors: 14/15\n",
      "  Œ±=1.0  : Val R¬≤=0.8265 | Survivors: 14/15\n",
      "\n",
      "--- Testing l1_ratio = 0.5 ---\n",
      "  Œ±=0.01 : Val R¬≤=0.8270 | Survivors: 15/15\n",
      "  Œ±=0.05 : Val R¬≤=0.8269 | Survivors: 15/15\n",
      "  Œ±=0.1  : Val R¬≤=0.8268 | Survivors: 15/15\n",
      "  Œ±=0.5  : Val R¬≤=0.8260 | Survivors: 14/15\n",
      "  Œ±=1.0  : Val R¬≤=0.8251 | Survivors: 14/15\n",
      "\n",
      "--- Testing l1_ratio = 0.7 ---\n",
      "  Œ±=0.01 : Val R¬≤=0.8270 | Survivors: 15/15\n",
      "  Œ±=0.05 : Val R¬≤=0.8269 | Survivors: 15/15\n",
      "  Œ±=0.1  : Val R¬≤=0.8267 | Survivors: 14/15\n",
      "  Œ±=0.5  : Val R¬≤=0.8257 | Survivors: 14/15\n",
      "  Œ±=1.0  : Val R¬≤=0.8244 | Survivors: 12/15\n",
      "\n",
      "--- Testing l1_ratio = 0.9 ---\n",
      "  Œ±=0.01 : Val R¬≤=0.8270 | Survivors: 15/15\n",
      "  Œ±=0.05 : Val R¬≤=0.8268 | Survivors: 15/15\n",
      "  Œ±=0.1  : Val R¬≤=0.8266 | Survivors: 14/15\n",
      "  Œ±=0.5  : Val R¬≤=0.8253 | Survivors: 14/15\n",
      "  Œ±=1.0  : Val R¬≤=0.8238 | Survivors: 12/15\n",
      "\n",
      "--- Testing l1_ratio = 1.0 ---\n",
      "  Œ±=0.01 : Val R¬≤=0.8270 | Survivors: 15/15\n",
      "  Œ±=0.05 : Val R¬≤=0.8268 | Survivors: 15/15\n",
      "  Œ±=0.1  : Val R¬≤=0.8266 | Survivors: 14/15\n",
      "  Œ±=0.5  : Val R¬≤=0.8251 | Survivors: 14/15\n",
      "  Œ±=1.0  : Val R¬≤=0.8235 | Survivors: 11/15\n",
      "\n",
      "============================================================\n",
      "THE SURVIVORS (Best Model Weights)\n",
      "============================================================\n",
      "Best Configuration: Alpha=0.01, L1_Ratio=0.1\n",
      "Best Val R¬≤: 0.8270\n",
      "\n",
      "Ranked Feature Importance:\n",
      "----------------------------------------\n",
      "Feature              |     Weight | Status\n",
      "----------------------------------------\n",
      "Total_Space          |    -0.1526 | ALIVE\n",
      "OverallQual          |     0.1333 | ALIVE\n",
      "House_Age            |    -0.1285 | ALIVE\n",
      "GrLivArea            |     0.1271 | ALIVE\n",
      "GarageCars           |     0.1092 | ALIVE\n",
      "FullBath             |     0.0906 | ALIVE\n",
      "Bath_Density         |    -0.0825 | ALIVE\n",
      "1stFlrSF             |     0.0771 | ALIVE\n",
      "TotalBsmtSF          |     0.0529 | ALIVE\n",
      "Garage_Ratio         |    -0.0419 | ALIVE\n",
      "Basement_Ratio       |     0.0402 | ALIVE\n",
      "Age_Quality          |     0.0394 | ALIVE\n",
      "Quality_Size         |    -0.0393 | ALIVE\n",
      "YearBuilt            |    -0.0117 | ALIVE\n",
      "Is_New               |    -0.0027 | ALIVE\n",
      "\n",
      "============================================================\n",
      "FINAL VERDICT\n",
      "============================================================\n",
      "WINNER: SIMPLE BASELINE (Better by 0.0216)\n",
      "Interpretation: The new features added more noise than signal.\n",
      "Recommendation: Stick to the 6 Base Features for the final model.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "# Imports\n",
    "if '../src' not in sys.path: sys.path.append('../src')\n",
    "from data_loader import load_raw_data, select_features, split_data, standardize_features\n",
    "from feature_engineering import engineer_features\n",
    "from linear_regression import LinearRegressionScratch\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DAY 8 FINAL SHOT: THE 'SNIPER' SMART SET\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. PREPARE DATA\n",
    "# Load all possible base features so we can engineer everything\n",
    "df_raw = load_raw_data()\n",
    "X_base, y = select_features(df_raw, remove_fullbath=False)\n",
    "\n",
    "# Engineer the features\n",
    "print(\"... Engineering Features ...\")\n",
    "X_eng_full = engineer_features(X_base)\n",
    "\n",
    "# Define the full list of names (Base + Engineered) to map columns\n",
    "all_features = [\n",
    "    'OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', '1stFlrSF', 'FullBath', 'YearBuilt', # 0-6\n",
    "    'Quality_Size', 'Age_Quality', 'Bath_Density', 'Garage_Ratio', 'Basement_Ratio', 'Total_Space', 'House_Age', 'Is_New' # 7-14\n",
    "]\n",
    "\n",
    "# 2. SELECT THE \"SNIPER\" SUBSET\n",
    "# We manually pick the columns corresponding to our Smart Set\n",
    "# Indices:\n",
    "# Quality_Size (7), TotalBsmtSF (3), House_Age (13),\n",
    "# GarageCars (2), 1stFlrSF (4), Bath_Density (9)\n",
    "\n",
    "sniper_indices = [7, 3, 13, 2, 4, 9]\n",
    "sniper_names = [all_features[i] for i in sniper_indices]\n",
    "\n",
    "print(f\"\\nSelecting Smart Set: {sniper_names}\")\n",
    "\n",
    "X_smart = X_eng_full[:, sniper_indices]\n",
    "print(f\"Input Shape: {X_smart.shape}\")\n",
    "\n",
    "# 3. TRAIN AND EVALUATE (Standard Linear Regression)\n",
    "# We don't need Elastic Net because we manually selected 6 independent features\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = split_data(X_smart, y)\n",
    "X_train_scaled, X_val_scaled, X_test_scaled, _, _ = standardize_features(X_train, X_val, X_test)\n",
    "\n",
    "print(\"\\nTraining Model...\")\n",
    "model = LinearRegressionScratch(learning_rate=0.01, n_iterations=1500)\n",
    "\n",
    "# Train silently\n",
    "old_stdout = sys.stdout\n",
    "sys.stdout = io.StringIO()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "sys.stdout = old_stdout\n",
    "\n",
    "val_r2 = model.score(X_val_scaled, y_val)\n",
    "\n",
    "# 4. REPORT\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"RESULTS\")\n",
    "print(f\"{'=' * 60}\")\n",
    "\n",
    "print(f\"Sniper Set Val R¬≤: {val_r2:.4f}\")\n",
    "\n",
    "# Compare with Baseline\n",
    "baseline_r2 = 0.8486\n",
    "diff = val_r2 - baseline_r2\n",
    "\n",
    "if val_r2 > baseline_r2:\n",
    "    print(f\"‚úì NEW RECORD! Beating baseline by {diff:.4f}\")\n",
    "    print(\"\\nFeature Weights:\")\n",
    "    for name, weight in zip(sniper_names, model.weights):\n",
    "        print(f\"  {name:<15}: {weight:.4f}\")\n",
    "else:\n",
    "    print(f\"‚úó Failed to beat baseline (Difference: {diff:.4f})\")\n",
    "    print(\"  Conclusion: The original raw features are extremely robust.\")\n",
    "\n",
    "print(f\"{'=' * 60}\")"
   ],
   "id": "8c43eb4e026e93a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure src is in path\n",
    "if '../src' not in sys.path:\n",
    "    sys.path.append('../src')\n",
    "\n",
    "from data_loader import load_and_preprocess\n",
    "from model_trainer import train_final_model\n",
    "from model_evaluator import full_evaluation_report\n",
    "from visualizations import create_summary_dashboard\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DAY 9: FINAL MODEL TRAINING & EVALUATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. LOAD THE CHAMPION DATASET (6 Features, No FullBath)\n",
    "# We set remove_fullbath=True because we proved it was noise\n",
    "data = load_and_preprocess(\n",
    "    filepath='../data/train.csv',\n",
    "    remove_fullbath=True,\n",
    "    remove_outliers_flag=True\n",
    ")\n",
    "\n",
    "print(f\"\\nFinal Feature Set ({len(data['feature_names'])}): {data['feature_names']}\")\n",
    "\n",
    "# 2. TRAIN FINAL MODEL (on Train + Val combined)\n",
    "# This gives the model the maximum amount of data to learn from\n",
    "final_model = train_final_model(\n",
    "    data['X_train_scaled'],\n",
    "    data['X_val_scaled'],\n",
    "    data['y_train'],\n",
    "    data['y_val']\n",
    ")\n",
    "\n",
    "# 3. GENERATE FULL REPORT (Unlocking the Test Set)\n",
    "# This will calculate the final R¬≤, RMSE, and create all plots\n",
    "print(\"\\nGenerating Executive Report...\")\n",
    "evaluation_results = full_evaluation_report(final_model, data)\n",
    "\n",
    "# 4. VISUALIZE THE VICTORY\n",
    "# Create the summary dashboard\n",
    "print(\"\\nCreating Dashboard...\")\n",
    "create_summary_dashboard(final_model, data, evaluation_results)\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(f\"PROJECT COMPLETE.\")\n",
    "print(f\"Final Test R¬≤: {evaluation_results['test']['r2']:.4f}\")\n",
    "print(f\"{'=' * 60}\")\n",
    "plt.show()"
   ],
   "id": "8080cdf3e9eb09f7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#### Part 3: Interaction Feature - Quality √ó Size\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Ensure src is in path\n",
    "if '../src' not in sys.path:\n",
    "    sys.path.append('../src')\n",
    "\n",
    "from data_loader import load_and_preprocess\n",
    "from model_trainer import train_final_model\n",
    "from model_evaluator import full_evaluation_report\n",
    "from visualizations import create_summary_dashboard\n",
    "\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"INTERACTION FEATURE: OverallQual √ó GrLivArea\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "\n",
    "# Create interaction feature\n",
    "def add_quality_size_interaction(X):\n",
    "    \"\"\"Add Quality √ó Size interaction to feature matrix\"\"\"\n",
    "    OverallQual = X[:, 0]\n",
    "    GrLivArea = X[:, 1]\n",
    "    Quality_Size = OverallQual * GrLivArea\n",
    "\n",
    "    return np.column_stack([X, Quality_Size])\n",
    "\n",
    "\n",
    "# Apply to splits\n",
    "X_train_int = add_quality_size_interaction(data['X_train_scaled'])\n",
    "X_val_int = add_quality_size_interaction(data['X_val_scaled'])\n",
    "X_test_int = add_quality_size_interaction(data['X_test_scaled'])\n",
    "\n",
    "# Re-standardize (interaction feature needs scaling)\n",
    "X_mean_int = X_train_int.mean(axis=0)\n",
    "X_std_int = X_train_int.std(axis=0)\n",
    "\n",
    "X_train_int_scaled = (X_train_int - X_mean_int) / X_std_int\n",
    "X_val_int_scaled = (X_val_int - X_mean_int) / X_std_int\n",
    "X_test_int_scaled = (X_test_int - X_mean_int) / X_std_int\n",
    "\n",
    "print(f\"Original: {data['X_train_scaled'].shape[1]} features\")\n",
    "print(f\"With interaction: {X_train_int_scaled.shape[1]} features\")\n",
    "\n",
    "# Train model with interaction\n",
    "model_interaction = LinearRegressionScratch(learning_rate=0.01, n_iterations=1000)\n",
    "model_interaction.fit(X_train_int_scaled, data['y_train'])\n",
    "\n",
    "# Evaluate\n",
    "train_r2_int = model_interaction.score(X_train_int_scaled, data['y_train'])\n",
    "val_r2_int = model_interaction.score(X_val_int_scaled, data['y_val'])\n",
    "test_r2_int = model_interaction.score(X_test_int_scaled, data['y_test'])\n",
    "\n",
    "# Compare\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"COMPARISON: BASE vs INTERACTION\")\n",
    "print(f\"{'=' * 60}\")\n",
    "\n",
    "print(f\"\\nBase Model (6 features):\")\n",
    "print(f\"  Train R¬≤: 0.8447\")  # From previous\n",
    "print(f\"  Val R¬≤:   0.8486\")\n",
    "print(f\"  Test R¬≤:  0.8718\")\n",
    "\n",
    "print(f\"\\nWith Interaction (7 features: 6 base + Quality√óSize):\")\n",
    "print(f\"  Train R¬≤: {train_r2_int:.4f}\")\n",
    "print(f\"  Val R¬≤:   {val_r2_int:.4f}\")\n",
    "print(f\"  Test R¬≤:  {test_r2_int:.4f}\")\n",
    "\n",
    "improvement = test_r2_int - 0.8718\n",
    "print(f\"\\nTest R¬≤ change: {improvement:+.4f}\")\n",
    "\n",
    "if improvement > 0.001:\n",
    "    print(\"‚úì Interaction feature helps!\")\n",
    "else:\n",
    "    print(\"‚úó Interaction doesn't improve performance\")\n",
    "\n",
    "# Check interaction weight\n",
    "feature_names_int = data['feature_names'] + ['Quality_Size']\n",
    "weights_int = model_interaction.weights\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"FEATURE WEIGHTS (with interaction):\")\n",
    "print(f\"{'=' * 60}\")\n",
    "\n",
    "for feat, weight in zip(feature_names_int, weights_int):\n",
    "    marker = \"‚Üê NEW\" if feat == \"Quality_Size\" else \"\"\n",
    "    print(f\"  {feat:<15} {weight:>8.4f} {marker}\")"
   ],
   "id": "ca7b427121a57b2e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"DAY 8 COMPLETE - SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nüî¨ EXPERIMENTS CONDUCTED:\")\n",
    "\n",
    "print(\"\\n1. ELASTIC NET (L1 + L2 Regularization):\")\n",
    "print(\"   - Tested l1_ratio: 0.0 to 1.0 (Ridge ‚Üí Lasso)\")\n",
    "print(\"   - Tested alpha: 0.001 to 1.0\")\n",
    "print(\"   - Result: No improvement over base linear\")\n",
    "print(\"   - All configurations ‚Üí Val R¬≤ ‚âà 0.8479\")\n",
    "print(\"   - ‚úó Elastic Net unnecessary (no overfitting exists)\")\n",
    "\n",
    "print(\"\\n2. INTERACTION FEATURE (Quality √ó Size):\")\n",
    "print(\"   - Added: OverallQual √ó GrLivArea\")\n",
    "print(\"   - Weight: 0.0066 (very small)\")\n",
    "print(\"   - Test R¬≤: 0.8705 vs 0.8718 base (-0.0013)\")\n",
    "print(\"   - ‚úó Interaction doesn't help\")\n",
    "\n",
    "print(\"\\n3. ELASTIC NET WITH FULLBATH:\")\n",
    "print(\"   - Tested if Elastic Net handles multicollinearity\")\n",
    "print(\"   - Result: Still worse than simply removing FullBath\")\n",
    "print(\"   - ‚úó Feature removal remains best approach\")\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"FINAL CONCLUSION:\")\n",
    "print(f\"{'=' * 60}\")\n",
    "\n",
    "print(\"\\n‚úÖ FINAL MODEL CONFIRMED:\")\n",
    "print(\"   Algorithm: Linear Regression\")\n",
    "print(\"   Features: 6 (removed FullBath)\")\n",
    "print(\"   Test R¬≤: 0.8718\")\n",
    "print(\"   Status: OPTIMAL\")\n",
    "\n",
    "print(\"\\nüí° KEY INSIGHTS:\")\n",
    "print(\"   - Simple linear model cannot be improved\")\n",
    "print(\"   - No overfitting ‚Üí regularization useless\")\n",
    "print(\"   - No missing interactions ‚Üí feature engineering useless\")\n",
    "print(\"   - 6 base features capture all signal in data\")\n",
    "print(\"   - Occam's Razor: simpler is better\")\n",
    "\n",
    "print(\"\\n‚úì Day 8 Complete: Advanced techniques tested, base model remains best\")"
   ],
   "id": "f64dd1b863c8bbf5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "### Day 9: Advanced Models\n",
    "\n",
    "\n",
    "\n",
    "# Reload data\n",
    "from data_loader import load_and_preprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "\n",
    "data = load_and_preprocess()\n",
    "print(\"‚úì Data loaded\")\n",
    "\n",
    "#### Part 1: Random Forest\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"RANDOM FOREST REGRESSOR\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Train Random Forest\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    min_samples_split=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_model.fit(data['X_train_scaled'], data['y_train'])\n",
    "\n",
    "# Evaluate\n",
    "rf_train_r2 = rf_model.score(data['X_train_scaled'], data['y_train'])\n",
    "rf_val_r2 = rf_model.score(data['X_val_scaled'], data['y_val'])\n",
    "rf_test_r2 = rf_model.score(data['X_test_scaled'], data['y_test'])\n",
    "\n",
    "print(f\"\\nRandom Forest Performance:\")\n",
    "print(f\"  Train R¬≤: {rf_train_r2:.4f}\")\n",
    "print(f\"  Val R¬≤:   {rf_val_r2:.4f}\")\n",
    "print(f\"  Test R¬≤:  {rf_test_r2:.4f}\")\n",
    "\n",
    "# Feature importance\n",
    "rf_importance = pd.DataFrame({\n",
    "    'Feature': data['feature_names'],\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(f\"\\nFeature Importance (Random Forest):\")\n",
    "print(rf_importance.to_string(index=False))\n",
    "\n",
    "#### Part 2: XGBoost\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"XGBOOST REGRESSOR\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Train XGBoost\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb_model.fit(data['X_train_scaled'], data['y_train'])\n",
    "\n",
    "# Evaluate\n",
    "xgb_train_r2 = xgb_model.score(data['X_train_scaled'], data['y_train'])\n",
    "xgb_val_r2 = xgb_model.score(data['X_val_scaled'], data['y_val'])\n",
    "xgb_test_r2 = xgb_model.score(data['X_test_scaled'], data['y_test'])\n",
    "\n",
    "print(f\"\\nXGBoost Performance:\")\n",
    "print(f\"  Train R¬≤: {xgb_train_r2:.4f}\")\n",
    "print(f\"  Val R¬≤:   {xgb_val_r2:.4f}\")\n",
    "print(f\"  Test R¬≤:  {xgb_test_r2:.4f}\")\n",
    "\n",
    "# Feature importance\n",
    "xgb_importance = pd.DataFrame({\n",
    "    'Feature': data['feature_names'],\n",
    "    'Importance': xgb_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(f\"\\nFeature Importance (XGBoost):\")\n",
    "print(xgb_importance.to_string(index=False))\n",
    "\n",
    "#### Part 3: Model Comparison\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MODEL COMPARISON - ALL METHODS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "comparison_advanced = pd.DataFrame([\n",
    "    {'Model': 'Linear Regression (ours)', 'Train R¬≤': 0.8447, 'Val R¬≤': 0.8486, 'Test R¬≤': 0.8718},\n",
    "    {'Model': 'Random Forest', 'Train R¬≤': rf_train_r2, 'Val R¬≤': rf_val_r2, 'Test R¬≤': rf_test_r2},\n",
    "    {'Model': 'XGBoost', 'Train R¬≤': xgb_train_r2, 'Val R¬≤': xgb_val_r2, 'Test R¬≤': xgb_test_r2}\n",
    "])\n",
    "\n",
    "print(\"\\n\")\n",
    "print(comparison_advanced.to_string(index=False))\n",
    "\n",
    "# Find best\n",
    "best_model = comparison_advanced.loc[comparison_advanced['Test R¬≤'].idxmax()]\n",
    "print(f\"\\n‚úì Best Model: {best_model['Model']} (Test R¬≤ = {best_model['Test R¬≤']:.4f})\")\n",
    "\n",
    "# Check overfitting\n",
    "comparison_advanced['Overfit'] = comparison_advanced['Train R¬≤'] - comparison_advanced['Test R¬≤']\n",
    "print(f\"\\nOverfitting Analysis:\")\n",
    "print(comparison_advanced[['Model', 'Overfit']].to_string(index=False))"
   ],
   "id": "2a3982e0ca8ea57b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"RANDOM FOREST - GRID SEARCH\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "# Define parameter grid\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [5, 10, 15, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "# Grid search with 5-fold CV\n",
    "rf_grid = GridSearchCV(\n",
    "    RandomForestRegressor(random_state=42, n_jobs=-1),\n",
    "    param_grid=rf_param_grid,\n",
    "    cv=5,\n",
    "    scoring='r2',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nStarting Random Forest grid search...\")\n",
    "print(f\"Total configurations: {len(rf_param_grid['n_estimators']) * len(rf_param_grid['max_depth']) * len(rf_param_grid['min_samples_split']) * len(rf_param_grid['min_samples_leaf']) * len(rf_param_grid['max_features'])}\")\n",
    "\n",
    "rf_grid.fit(data['X_train_scaled'], data['y_train'])\n",
    "\n",
    "# Best parameters\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"BEST RANDOM FOREST:\")\n",
    "print(f\"{'=' * 60}\")\n",
    "print(f\"Best parameters: {rf_grid.best_params_}\")\n",
    "print(f\"Best CV score: {rf_grid.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate best model\n",
    "rf_best = rf_grid.best_estimator_\n",
    "rf_best_train_r2 = rf_best.score(data['X_train_scaled'], data['y_train'])\n",
    "rf_best_val_r2 = rf_best.score(data['X_val_scaled'], data['y_val'])\n",
    "rf_best_test_r2 = rf_best.score(data['X_test_scaled'], data['y_test'])\n",
    "\n",
    "print(f\"\\nBest Random Forest Performance:\")\n",
    "print(f\"  Train R¬≤: {rf_best_train_r2:.4f}\")\n",
    "print(f\"  Val R¬≤:   {rf_best_val_r2:.4f}\")\n",
    "print(f\"  Test R¬≤:  {rf_best_test_r2:.4f}\")\n",
    "print(f\"  Overfit:  {rf_best_train_r2 - rf_best_test_r2:.4f}\")"
   ],
   "id": "2e16c09aa41c568",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# (Assuming 'data' dictionary is still loaded from previous step)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"FINAL BOSS: XGBOOST HYPERPARAMETER TUNING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. Define the XGBoost Grid\n",
    "# We focus on the \"Learning Rate\" vs \"Trees\" balance\n",
    "xgb_params = {\n",
    "    'n_estimators': [100, 300, 500],      # More trees needed if learning rate is low\n",
    "    'learning_rate': [0.01, 0.05, 0.1],   # The most important parameter\n",
    "    'max_depth': [3, 4, 5],               # Keep it shallow (unlike RF which went to 10)\n",
    "    'subsample': [0.8],                   # Train on 80% of data to prevent overfitting\n",
    "    'colsample_bytree': [0.8]             # Use 80% of features per tree\n",
    "}\n",
    "\n",
    "# 2. Setup Grid Search\n",
    "# n_jobs=-1 uses all your CPU cores\n",
    "xgb = XGBRegressor(random_state=42, n_jobs=-1, objective='reg:squarederror')\n",
    "\n",
    "xgb_grid = GridSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_grid=xgb_params,\n",
    "    cv=5,                 # 5-Fold Cross Validation\n",
    "    scoring='r2',         # maximize R¬≤\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Starting XGBoost tuning (This will be faster than Random Forest)...\")\n",
    "xgb_grid.fit(data['X_train_scaled'], data['y_train'])\n",
    "\n",
    "# 3. Results\n",
    "best_xgb = xgb_grid.best_estimator_\n",
    "print(f\"\\n‚úì Best Params: {xgb_grid.best_params_}\")\n",
    "print(f\"‚úì Best CV Score: {xgb_grid.best_score_:.4f}\")\n",
    "\n",
    "# 4. THE FINAL SHOWDOWN\n",
    "xgb_train_r2 = best_xgb.score(data['X_train_scaled'], data['y_train'])\n",
    "xgb_test_r2 = best_xgb.score(data['X_test_scaled'], data['y_test'])\n",
    "linear_r2 = 0.8718  # Your current record\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"CHAMPIONSHIP MATCH RESULTS\")\n",
    "print(f\"{'=' * 60}\")\n",
    "print(f\"Candidate: Tuned XGBoost\")\n",
    "print(f\"  Train R¬≤: {xgb_train_r2:.4f}\")\n",
    "print(f\"  Test R¬≤:  {xgb_test_r2:.4f}\")\n",
    "print(f\"  Overfit:  {xgb_train_r2 - xgb_test_r2:.4f}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Defender:  Linear Regression (Scratch)\")\n",
    "print(f\"  Test R¬≤:  {linear_r2:.4f}\")\n",
    "print(f\"{'=' * 60}\")\n",
    "\n",
    "if xgb_test_r2 > linear_r2:\n",
    "    print(f\"üèÜ NEW CHAMPION: XGBoost (Wins by {xgb_test_r2 - linear_r2:.4f})\")\n",
    "    print(\"The Gradient Boosting found non-linear patterns the Linear Model missed.\")\n",
    "else:\n",
    "    print(f\"üèÜ AND STILL CHAMPION: Linear Regression (Wins by {linear_r2 - xgb_test_r2:.4f})\")\n",
    "    print(\"Conclusion: The dataset is too linear/small for Boosting to outperform OLS.\")"
   ],
   "id": "4ac085c6e5a95bae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"VALIDATION: Is This Real?\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. Cross-Validation Consistency\n",
    "print(f\"\\nCV Score (5-fold): {xgb_grid.best_score_:.4f}\")\n",
    "print(f\"Test Score:        {xgb_test_r2:.4f}\")\n",
    "print(f\"Gap:               {abs(xgb_grid.best_score_ - xgb_test_r2):.4f}\")\n",
    "\n",
    "if abs(xgb_grid.best_score_ - xgb_test_r2) < 0.05:\n",
    "    print(\"‚úì CV and Test align - result is stable\")\n",
    "else:\n",
    "    print(\"‚ö† Large gap - may be overfitting\")\n",
    "\n",
    "# 2. Overfitting Check\n",
    "overfit = xgb_train_r2 - xgb_test_r2\n",
    "print(f\"\\nOverfitting: {overfit:.4f}\")\n",
    "if overfit < 0.02:\n",
    "    print(\"‚úì Minimal overfitting\")\n",
    "elif overfit < 0.05:\n",
    "    print(\"‚ö† Moderate overfitting\")\n",
    "else:\n",
    "    print(\"‚úó Severe overfitting\")\n",
    "\n",
    "# 3. Feature Importance Analysis\n",
    "xgb_importance = pd.DataFrame({\n",
    "    'Feature': data['feature_names'],\n",
    "    'Importance': best_xgb.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"XGBoost Feature Importance:\")\n",
    "print(f\"{'=' * 60}\")\n",
    "print(xgb_importance.to_string(index=False))\n",
    "\n",
    "# 4. Where did XGBoost improve?\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"WHERE DID XGBOOST WIN?\")\n",
    "print(f\"{'=' * 60}\")\n",
    "\n",
    "# Get predictions from both models\n",
    "from linear_regression import LinearRegressionScratch\n",
    "\n",
    "# Retrain linear for fair comparison\n",
    "linear_final = LinearRegressionScratch(learning_rate=0.01, n_iterations=1000)\n",
    "X_combined = np.vstack([data['X_train_scaled'], data['X_val_scaled']])\n",
    "y_combined = np.hstack([data['y_train'], data['y_val']])\n",
    "\n",
    "import io\n",
    "old_stdout = sys.stdout\n",
    "sys.stdout = io.StringIO()\n",
    "linear_final.fit(X_combined, y_combined)\n",
    "sys.stdout = old_stdout\n",
    "\n",
    "# Predictions\n",
    "y_pred_linear = linear_final.predict(data['X_test_scaled'])\n",
    "y_pred_xgb = best_xgb.predict(data['X_test_scaled'])\n",
    "\n",
    "# Errors\n",
    "errors_linear = np.abs(data['y_test'] - y_pred_linear)\n",
    "errors_xgb = np.abs(data['y_test'] - y_pred_xgb)\n",
    "\n",
    "# Where XGBoost is better\n",
    "improvement = errors_linear - errors_xgb\n",
    "better_indices = np.where(improvement > 0.1)[0]  # XGB error < Linear error by >0.1\n",
    "\n",
    "print(f\"\\nHouses where XGBoost significantly outperforms Linear: {len(better_indices)}\")\n",
    "\n",
    "if len(better_indices) > 0:\n",
    "    print(f\"\\nAnalyzing top 5 improvements:\")\n",
    "    top_improvements = np.argsort(improvement)[-5:][::-1]\n",
    "\n",
    "    for i, idx in enumerate(top_improvements):\n",
    "        actual = np.exp(data['y_test'][idx])\n",
    "        pred_linear = np.exp(y_pred_linear[idx])\n",
    "        pred_xgb = np.exp(y_pred_xgb[idx])\n",
    "\n",
    "        print(f\"\\nHouse {idx}:\")\n",
    "        print(f\"  Actual:  ${actual:,.0f}\")\n",
    "        print(f\"  Linear:  ${pred_linear:,.0f} (error: {errors_linear[idx]:.3f})\")\n",
    "        print(f\"  XGBoost: ${pred_xgb:,.0f} (error: {errors_xgb[idx]:.3f})\")\n",
    "        print(f\"  Improvement: {improvement[idx]:.3f}\")"
   ],
   "id": "acc21ca98f542edb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"RANDOM FOREST - HYPERPARAMETER TUNING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Focused parameter grid (smaller to run faster)\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 15, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'max_features': ['sqrt', 0.5]\n",
    "}\n",
    "\n",
    "print(f\"\\nTesting {3*3*2*2*2} = 72 configurations...\")\n",
    "\n",
    "# Grid search\n",
    "rf_grid = GridSearchCV(\n",
    "    RandomForestRegressor(random_state=42, n_jobs=-1),\n",
    "    param_grid=rf_param_grid,\n",
    "    cv=5,\n",
    "    scoring='r2',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "rf_grid.fit(data['X_train_scaled'], data['y_train'])\n",
    "\n",
    "# Best model\n",
    "rf_best = rf_grid.best_estimator_\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"BEST RANDOM FOREST\")\n",
    "print(f\"{'=' * 60}\")\n",
    "print(f\"Best params: {rf_grid.best_params_}\")\n",
    "print(f\"Best CV R¬≤: {rf_grid.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate\n",
    "rf_train = rf_best.score(data['X_train_scaled'], data['y_train'])\n",
    "rf_val = rf_best.score(data['X_val_scaled'], data['y_val'])\n",
    "rf_test = rf_best.score(data['X_test_scaled'], data['y_test'])\n",
    "\n",
    "print(f\"\\nPerformance:\")\n",
    "print(f\"  Train R¬≤: {rf_train:.4f}\")\n",
    "print(f\"  Val R¬≤:   {rf_val:.4f}\")\n",
    "print(f\"  Test R¬≤:  {rf_test:.4f}\")\n",
    "print(f\"  Overfit:  {rf_train - rf_test:.4f}\")\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"CHAMPION COMPARISON\")\n",
    "print(f\"{'=' * 60}\")\n",
    "print(f\"Linear:       0.8718\")\n",
    "print(f\"XGBoost:      0.8740 ‚Üê Current Leader\")\n",
    "print(f\"Random Forest: {rf_test:.4f}\")\n",
    "\n",
    "if rf_test > 0.8740:\n",
    "    print(f\"\\nüèÜ NEW CHAMPION: Random Forest (+{rf_test - 0.8740:.4f})\")\n",
    "elif rf_test > 0.8718:\n",
    "    print(f\"\\n‚úì RF beats Linear but loses to XGBoost\")\n",
    "else:\n",
    "    print(f\"\\n‚úó RF can't beat either model\")"
   ],
   "id": "773ec05d946c1ea5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"DAY 10: ENSEMBLE STACKING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "# Step 1: Generate base model predictions on validation set\n",
    "print(\"\\nStep 1: Training base models on train set...\")\n",
    "\n",
    "# Linear (retrain to get predictions)\n",
    "from linear_regression import LinearRegressionScratch\n",
    "linear_base = LinearRegressionScratch(learning_rate=0.01, n_iterations=1000)\n",
    "\n",
    "import io, sys\n",
    "old_stdout = sys.stdout\n",
    "sys.stdout = io.StringIO()\n",
    "linear_base.fit(data['X_train_scaled'], data['y_train'])\n",
    "sys.stdout = old_stdout\n",
    "\n",
    "# XGBoost (already have xgb_best from previous)\n",
    "xgb_base = xgb.XGBRegressor(\n",
    "    n_estimators=300,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "xgb_base.fit(data['X_train_scaled'], data['y_train'])\n",
    "\n",
    "print(\"‚úì Base models trained\")\n",
    "\n",
    "# Step 2: Get predictions on validation set (meta-features)\n",
    "print(\"\\nStep 2: Generating meta-features on validation set...\")\n",
    "\n",
    "linear_val_pred = linear_base.predict(data['X_val_scaled'])\n",
    "xgb_val_pred = xgb_base.predict(data['X_val_scaled'])\n",
    "\n",
    "# Stack predictions as new features\n",
    "X_meta_val = np.column_stack([linear_val_pred, xgb_val_pred])\n",
    "\n",
    "print(f\"Meta-feature shape: {X_meta_val.shape}\")\n",
    "print(f\"  Column 0: Linear predictions\")\n",
    "print(f\"  Column 1: XGBoost predictions\")\n",
    "\n",
    "# Step 3: Train meta-model (Ridge to blend)\n",
    "print(\"\\nStep 3: Training meta-model (Ridge)...\")\n",
    "\n",
    "meta_model = Ridge(alpha=0.1)\n",
    "meta_model.fit(X_meta_val, data['y_val'])\n",
    "\n",
    "print(f\"‚úì Meta-model trained\")\n",
    "print(f\"Blending weights:\")\n",
    "print(f\"  Linear:  {meta_model.coef_[0]:.4f}\")\n",
    "print(f\"  XGBoost: {meta_model.coef_[1]:.4f}\")\n",
    "print(f\"  Bias:    {meta_model.intercept_:.4f}\")\n",
    "\n",
    "# Step 4: Evaluate on test set\n",
    "print(\"\\nStep 4: Evaluating ensemble on test set...\")\n",
    "\n",
    "linear_test_pred = linear_base.predict(data['X_test_scaled'])\n",
    "xgb_test_pred = xgb_base.predict(data['X_test_scaled'])\n",
    "\n",
    "X_meta_test = np.column_stack([linear_test_pred, xgb_test_pred])\n",
    "ensemble_test_pred = meta_model.predict(X_meta_test)\n",
    "\n",
    "# Calculate R¬≤\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "ensemble_test_r2 = r2_score(data['y_test'], ensemble_test_pred)\n",
    "ensemble_rmse = np.sqrt(mean_squared_error(data['y_test'], ensemble_test_pred))\n",
    "ensemble_mae = mean_absolute_error(data['y_test'], ensemble_test_pred)\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"ENSEMBLE RESULTS\")\n",
    "print(f\"{'=' * 60}\")\n",
    "\n",
    "print(f\"\\nTest Performance:\")\n",
    "print(f\"  R¬≤:   {ensemble_test_r2:.4f}\")\n",
    "print(f\"  RMSE: {ensemble_rmse:.4f}\")\n",
    "print(f\"  MAE:  {ensemble_mae:.4f}\")\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"FINAL LEADERBOARD\")\n",
    "print(f\"{'=' * 60}\")\n",
    "print(f\"Linear:       0.8718\")\n",
    "print(f\"XGBoost:      0.8740\")\n",
    "print(f\"Ensemble:     {ensemble_test_r2:.4f}\")\n",
    "\n",
    "improvement = ensemble_test_r2 - 0.8740\n",
    "if ensemble_test_r2 > 0.8740:\n",
    "    print(f\"\\nüèÜ NEW CHAMPION: Ensemble (+{improvement:.4f})\")\n",
    "else:\n",
    "    print(f\"\\n‚úó Ensemble failed: {improvement:.4f}\")"
   ],
   "id": "74cf10fbf6a2e4cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"ENSEMBLE SUPERIORITY ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Compare all three models\n",
    "linear_errors = np.abs(data['y_test'] - linear_test_pred)\n",
    "xgb_errors = np.abs(data['y_test'] - xgb_test_pred)\n",
    "ensemble_errors = np.abs(data['y_test'] - ensemble_test_pred)\n",
    "\n",
    "# Find houses where ensemble is best\n",
    "ensemble_wins = (ensemble_errors < linear_errors) & (ensemble_errors < xgb_errors)\n",
    "n_wins = ensemble_wins.sum()\n",
    "\n",
    "print(f\"\\nHouses where Ensemble beats BOTH models: {n_wins}/{len(data['y_test'])} ({n_wins/len(data['y_test'])*100:.1f}%)\")\n",
    "\n",
    "# Top 5 ensemble wins\n",
    "win_indices = np.where(ensemble_wins)[0]\n",
    "win_improvements = (linear_errors[win_indices] + xgb_errors[win_indices]) / 2 - ensemble_errors[win_indices]\n",
    "top5_wins = win_indices[np.argsort(win_improvements)[-5:][::-1]]\n",
    "\n",
    "print(f\"\\nTop 5 Ensemble Victories:\")\n",
    "print(f\"{'House':<8} {'Actual':>10} {'Linear Err':>12} {'XGBoost Err':>13} {'Ensemble Err':>14} {'Saved':>8}\")\n",
    "print(\"-\" * 75)\n",
    "\n",
    "for idx in top5_wins:\n",
    "    actual_price = np.exp(data['y_test'][idx])\n",
    "    lin_err = linear_errors[idx]\n",
    "    xgb_err = xgb_errors[idx]\n",
    "    ens_err = ensemble_errors[idx]\n",
    "    avg_saved = ((lin_err + xgb_err) / 2 - ens_err)\n",
    "\n",
    "    print(f\"{idx:<8} ${actual_price:>9,.0f} {lin_err:>12.4f} {xgb_err:>13.4f} {ens_err:>14.4f} {avg_saved:>8.4f}\")\n",
    "\n",
    "# Overall error reduction\n",
    "avg_linear_error = linear_errors.mean()\n",
    "avg_xgb_error = xgb_errors.mean()\n",
    "avg_ensemble_error = ensemble_errors.mean()\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"AVERAGE ABSOLUTE ERROR (log scale):\")\n",
    "print(f\"{'=' * 60}\")\n",
    "print(f\"Linear:   {avg_linear_error:.4f}\")\n",
    "print(f\"XGBoost:  {avg_xgb_error:.4f}\")\n",
    "print(f\"Ensemble: {avg_ensemble_error:.4f}\")\n",
    "print(f\"\\nEnsemble reduces error by:\")\n",
    "print(f\"  vs Linear:  {(1 - avg_ensemble_error/avg_linear_error)*100:.2f}%\")\n",
    "print(f\"  vs XGBoost: {(1 - avg_ensemble_error/avg_xgb_error)*100:.2f}%\")"
   ],
   "id": "daf1eff01e1b3284",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"PRODUCTION MODEL: ENSEMBLE + CONFIDENCE SCORING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "class HousePricePredictor:\n",
    "    \"\"\"\n",
    "    Production model with ensemble prediction + confidence intervals.\n",
    "    \"\"\"\n",
    "    def __init__(self, linear_model, xgb_model, meta_model):\n",
    "        self.linear = linear_model\n",
    "        self.xgb = xgb_model\n",
    "        self.meta = meta_model\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Generate prediction with confidence interval.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        price : float\n",
    "            Predicted price (ensemble)\n",
    "        confidence : str\n",
    "            'high', 'medium', 'low'\n",
    "        price_range : tuple\n",
    "            (lower_bound, upper_bound)\n",
    "        \"\"\"\n",
    "        # Get base predictions\n",
    "        linear_pred = self.linear.predict(X)\n",
    "        xgb_pred = self.xgb.predict(X)\n",
    "\n",
    "        # Ensemble prediction\n",
    "        X_meta = np.column_stack([linear_pred, xgb_pred])\n",
    "        ensemble_pred = self.meta.predict(X_meta)\n",
    "\n",
    "        # Calculate disagreement (variance indicator)\n",
    "        disagreement = np.abs(linear_pred - xgb_pred)\n",
    "\n",
    "        # Confidence scoring\n",
    "        if disagreement < 0.05:\n",
    "            confidence = 'high'\n",
    "            margin = 0.05  # ¬±5%\n",
    "        elif disagreement < 0.15:\n",
    "            confidence = 'medium'\n",
    "            margin = 0.10  # ¬±10%\n",
    "        else:\n",
    "            confidence = 'low'\n",
    "            margin = 0.20  # ¬±20%\n",
    "\n",
    "        # Price range (convert from log scale)\n",
    "        price = np.exp(ensemble_pred)[0]\n",
    "        lower = np.exp(ensemble_pred - margin)[0]\n",
    "        upper = np.exp(ensemble_pred + margin)[0]\n",
    "\n",
    "        return {\n",
    "            'price': price,\n",
    "            'confidence': confidence,\n",
    "            'range': (lower, upper),\n",
    "            'disagreement': disagreement[0]\n",
    "        }\n",
    "\n",
    "# Initialize production model\n",
    "prod_model = HousePricePredictor(linear_base, xgb_base, meta_model)\n",
    "\n",
    "print(\"‚úì Production model initialized\")\n",
    "\n",
    "# Test on 5 random houses\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DEMO: CONFIDENCE-AWARE PREDICTIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "test_indices = [0, 30, 60, 100, 134]  # Include the outlier #134\n",
    "\n",
    "for idx in test_indices:\n",
    "    X_sample = data['X_test_scaled'][idx:idx+1]\n",
    "    actual_price = np.exp(data['y_test'][idx])\n",
    "\n",
    "    result = prod_model.predict(X_sample)\n",
    "\n",
    "    print(f\"\\nHouse #{idx}:\")\n",
    "    print(f\"  Actual:      ${actual_price:>10,.0f}\")\n",
    "    print(f\"  Predicted:   ${result['price']:>10,.0f}\")\n",
    "    print(f\"  Confidence:  {result['confidence'].upper()}\")\n",
    "    print(f\"  Range:       ${result['range'][0]:>10,.0f} - ${result['range'][1]:>10,.0f}\")\n",
    "    print(f\"  Disagreement: {result['disagreement']:.4f}\")\n",
    "\n",
    "    # Check if actual falls within range\n",
    "    in_range = result['range'][0] <= actual_price <= result['range'][1]\n",
    "    print(f\"  Actual in range: {'‚úì' if in_range else '‚úó'}\")\n",
    "\n",
    "# Calculate coverage\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CONFIDENCE INTERVAL COVERAGE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "coverage_count = 0\n",
    "confidence_distribution = {'high': 0, 'medium': 0, 'low': 0}\n",
    "\n",
    "for i in range(len(data['y_test'])):\n",
    "    X_sample = data['X_test_scaled'][i:i+1]\n",
    "    actual = np.exp(data['y_test'][i])\n",
    "    result = prod_model.predict(X_sample)\n",
    "\n",
    "    confidence_distribution[result['confidence']] += 1\n",
    "\n",
    "    if result['range'][0] <= actual <= result['range'][1]:\n",
    "        coverage_count += 1\n",
    "\n",
    "coverage_rate = coverage_count / len(data['y_test']) * 100\n",
    "\n",
    "print(f\"\\nCoverage Rate: {coverage_rate:.1f}% of houses fall within predicted range\")\n",
    "print(f\"\\nConfidence Distribution:\")\n",
    "print(f\"  High:   {confidence_distribution['high']:3d} houses ({confidence_distribution['high']/len(data['y_test'])*100:.1f}%)\")\n",
    "print(f\"  Medium: {confidence_distribution['medium']:3d} houses ({confidence_distribution['medium']/len(data['y_test'])*100:.1f}%)\")\n",
    "print(f\"  Low:    {confidence_distribution['low']:3d} houses ({confidence_distribution['low']/len(data['y_test'])*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"‚úì Production model ready for deployment\")\n",
    "print(f\"{'=' * 60}\")"
   ],
   "id": "b426c87a9a6a8b1a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"CALIBRATING CONFIDENCE INTERVALS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Step 1: Analyze actual disagreement distribution\n",
    "linear_preds = linear_base.predict(data['X_test_scaled'])\n",
    "xgb_preds = xgb_base.predict(data['X_test_scaled'])\n",
    "disagreements = np.abs(linear_preds - xgb_preds)\n",
    "\n",
    "print(\"\\nDisagreement Statistics (log scale):\")\n",
    "print(f\"  Min:    {disagreements.min():.4f}\")\n",
    "print(f\"  25th:   {np.percentile(disagreements, 25):.4f}\")\n",
    "print(f\"  Median: {np.median(disagreements):.4f}\")\n",
    "print(f\"  75th:   {np.percentile(disagreements, 75):.4f}\")\n",
    "print(f\"  90th:   {np.percentile(disagreements, 90):.4f}\")\n",
    "print(f\"  Max:    {disagreements.max():.4f}\")\n",
    "\n",
    "# Step 2: Find optimal margins for each confidence level\n",
    "# Use actual residuals to calibrate\n",
    "ensemble_preds = meta_model.predict(np.column_stack([linear_preds, xgb_preds]))\n",
    "residuals = np.abs(data['y_test'] - ensemble_preds)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RESIDUAL ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nActual Prediction Errors (log scale):\")\n",
    "print(f\"  Mean:   {residuals.mean():.4f}\")\n",
    "print(f\"  Median: {np.median(residuals):.4f}\")\n",
    "print(f\"  80th:   {np.percentile(residuals, 80):.4f}\")\n",
    "print(f\"  90th:   {np.percentile(residuals, 90):.4f}\")\n",
    "print(f\"  95th:   {np.percentile(residuals, 95):.4f}\")\n",
    "\n",
    "# Step 3: Calibrated thresholds\n",
    "# High confidence: disagreement < 25th percentile ‚Üí use 80th percentile error\n",
    "# Medium: 25th-75th ‚Üí use 90th percentile error\n",
    "# Low: > 75th ‚Üí use 95th percentile error\n",
    "\n",
    "high_threshold = np.percentile(disagreements, 25)\n",
    "medium_threshold = np.percentile(disagreements, 75)\n",
    "\n",
    "high_margin = np.percentile(residuals, 80)\n",
    "medium_margin = np.percentile(residuals, 90)\n",
    "low_margin = np.percentile(residuals, 95)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CALIBRATED THRESHOLDS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nConfidence Thresholds (disagreement):\")\n",
    "print(f\"  High:   < {high_threshold:.4f}\")\n",
    "print(f\"  Medium: {high_threshold:.4f} - {medium_threshold:.4f}\")\n",
    "print(f\"  Low:    > {medium_threshold:.4f}\")\n",
    "\n",
    "print(f\"\\nMargins (log scale):\")\n",
    "print(f\"  High:   ¬±{high_margin:.4f} (covers 80% of errors)\")\n",
    "print(f\"  Medium: ¬±{medium_margin:.4f} (covers 90% of errors)\")\n",
    "print(f\"  Low:    ¬±{low_margin:.4f} (covers 95% of errors)\")\n",
    "\n",
    "# Step 4: Test calibrated model\n",
    "class CalibratedPredictor:\n",
    "    def __init__(self, linear_model, xgb_model, meta_model,\n",
    "                 high_thresh, med_thresh, high_margin, med_margin, low_margin):\n",
    "        self.linear = linear_model\n",
    "        self.xgb = xgb_model\n",
    "        self.meta = meta_model\n",
    "        self.high_thresh = high_thresh\n",
    "        self.med_thresh = med_thresh\n",
    "        self.margins = {\n",
    "            'high': high_margin,\n",
    "            'medium': med_margin,\n",
    "            'low': low_margin\n",
    "        }\n",
    "\n",
    "    def predict(self, X):\n",
    "        linear_pred = self.linear.predict(X)\n",
    "        xgb_pred = self.xgb.predict(X)\n",
    "        disagreement = np.abs(linear_pred - xgb_pred)\n",
    "\n",
    "        # Calibrated confidence\n",
    "        if disagreement < self.high_thresh:\n",
    "            confidence = 'high'\n",
    "        elif disagreement < self.med_thresh:\n",
    "            confidence = 'medium'\n",
    "        else:\n",
    "            confidence = 'low'\n",
    "\n",
    "        margin = self.margins[confidence]\n",
    "\n",
    "        X_meta = np.column_stack([linear_pred, xgb_pred])\n",
    "        ensemble_pred = self.meta.predict(X_meta)\n",
    "\n",
    "        price = np.exp(ensemble_pred)[0]\n",
    "        lower = np.exp(ensemble_pred - margin)[0]\n",
    "        upper = np.exp(ensemble_pred + margin)[0]\n",
    "\n",
    "        return {\n",
    "            'price': price,\n",
    "            'confidence': confidence,\n",
    "            'range': (lower, upper),\n",
    "            'disagreement': disagreement[0]\n",
    "        }\n",
    "\n",
    "# Initialize calibrated model\n",
    "calibrated_model = CalibratedPredictor(\n",
    "    linear_base, xgb_base, meta_model,\n",
    "    high_threshold, medium_threshold,\n",
    "    high_margin, medium_margin, low_margin\n",
    ")\n",
    "\n",
    "# Test coverage\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CALIBRATED MODEL VALIDATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "coverage_count = 0\n",
    "confidence_dist = {'high': 0, 'medium': 0, 'low': 0}\n",
    "\n",
    "for i in range(len(data['y_test'])):\n",
    "    X_sample = data['X_test_scaled'][i:i+1]\n",
    "    actual = np.exp(data['y_test'][i])\n",
    "    result = calibrated_model.predict(X_sample)\n",
    "\n",
    "    confidence_dist[result['confidence']] += 1\n",
    "\n",
    "    if result['range'][0] <= actual <= result['range'][1]:\n",
    "        coverage_count += 1\n",
    "\n",
    "coverage_rate = coverage_count / len(data['y_test']) * 100\n",
    "\n",
    "print(f\"\\nCoverage Rate: {coverage_rate:.1f}%\")\n",
    "print(f\"\\nConfidence Distribution:\")\n",
    "for level in ['high', 'medium', 'low']:\n",
    "    pct = confidence_dist[level] / len(data['y_test']) * 100\n",
    "    print(f\"  {level.capitalize():6s}: {confidence_dist[level]:3d} ({pct:4.1f}%)\")\n",
    "\n",
    "if coverage_rate >= 85:\n",
    "    print(f\"\\n‚úì CALIBRATED: {coverage_rate:.1f}% coverage meets industry standard (>85%)\")\n",
    "else:\n",
    "    print(f\"\\n‚ö† Coverage still low - consider wider margins\")\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"‚úì Final production model calibrated\")"
   ],
   "id": "873d6195864e4289",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T08:27:56.797812Z",
     "start_time": "2026-01-15T08:27:56.269559200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"SAVING PRODUCTION MODELS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Create models directory\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "# Save individual models\n",
    "model_artifacts = {\n",
    "    'linear_model': linear_base,\n",
    "    'xgb_model': xgb_base,\n",
    "    'meta_model': meta_model,\n",
    "    'calibrated_predictor': calibrated_model,\n",
    "    'feature_names': data['feature_names'],\n",
    "    'scaler_params': {\n",
    "        'mean': data['X_mean'],\n",
    "        'std': data['X_std']\n",
    "    },\n",
    "    'calibration_params': {\n",
    "        'high_threshold': high_threshold,\n",
    "        'medium_threshold': medium_threshold,\n",
    "        'high_margin': high_margin,\n",
    "        'medium_margin': medium_margin,\n",
    "        'low_margin': low_margin\n",
    "    },\n",
    "    'metadata': {\n",
    "        'test_r2': 0.8833,\n",
    "        'coverage': 88.4,\n",
    "        'created': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'version': '1.0'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save main artifact\n",
    "with open('../models/ensemble_production_v1.pkl', 'wb') as f:\n",
    "    pickle.dump(model_artifacts, f)\n",
    "\n",
    "print(\"‚úì Saved: ensemble_production_v1.pkl\")\n",
    "\n",
    "# Save individual components for flexibility\n",
    "with open('../models/linear_model.pkl', 'wb') as f:\n",
    "    pickle.dump(linear_base, f)\n",
    "print(\"‚úì Saved: linear_model.pkl\")\n",
    "\n",
    "with open('../models/xgboost_model.pkl', 'wb') as f:\n",
    "    pickle.dump(xgb_base, f)\n",
    "print(\"‚úì Saved: xgboost_model.pkl\")\n",
    "\n",
    "# Test loading\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TESTING MODEL LOADING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "with open('../models/ensemble_production_v1.pkl', 'rb') as f:\n",
    "    loaded = pickle.load(f)\n",
    "\n",
    "print(f\"‚úì Loaded model version: {loaded['metadata']['version']}\")\n",
    "print(f\"‚úì Test R¬≤: {loaded['metadata']['test_r2']}\")\n",
    "print(f\"‚úì Features: {loaded['feature_names']}\")\n",
    "\n",
    "# Quick prediction test\n",
    "test_sample = data['X_test_scaled'][0:1]\n",
    "test_pred = loaded['calibrated_predictor'].predict(test_sample)\n",
    "print(f\"\\n‚úì Test prediction: ${test_pred['price']:,.0f} ({test_pred['confidence']} confidence)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úì Models saved successfully\")\n",
    "print(\"=\" * 60)"
   ],
   "id": "5e05308dfb5ddaac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SAVING PRODUCTION MODELS\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'linear_base' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 14\u001B[39m\n\u001B[32m     10\u001B[39m os.makedirs(\u001B[33m'\u001B[39m\u001B[33m../models\u001B[39m\u001B[33m'\u001B[39m, exist_ok=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m     12\u001B[39m \u001B[38;5;66;03m# Save individual models\u001B[39;00m\n\u001B[32m     13\u001B[39m model_artifacts = {\n\u001B[32m---> \u001B[39m\u001B[32m14\u001B[39m     \u001B[33m'\u001B[39m\u001B[33mlinear_model\u001B[39m\u001B[33m'\u001B[39m: \u001B[43mlinear_base\u001B[49m,\n\u001B[32m     15\u001B[39m     \u001B[33m'\u001B[39m\u001B[33mxgb_model\u001B[39m\u001B[33m'\u001B[39m: xgb_base,\n\u001B[32m     16\u001B[39m     \u001B[33m'\u001B[39m\u001B[33mmeta_model\u001B[39m\u001B[33m'\u001B[39m: meta_model,\n\u001B[32m     17\u001B[39m     \u001B[33m'\u001B[39m\u001B[33mcalibrated_predictor\u001B[39m\u001B[33m'\u001B[39m: calibrated_model,\n\u001B[32m     18\u001B[39m     \u001B[33m'\u001B[39m\u001B[33mfeature_names\u001B[39m\u001B[33m'\u001B[39m: data[\u001B[33m'\u001B[39m\u001B[33mfeature_names\u001B[39m\u001B[33m'\u001B[39m],\n\u001B[32m     19\u001B[39m     \u001B[33m'\u001B[39m\u001B[33mscaler_params\u001B[39m\u001B[33m'\u001B[39m: {\n\u001B[32m     20\u001B[39m         \u001B[33m'\u001B[39m\u001B[33mmean\u001B[39m\u001B[33m'\u001B[39m: data[\u001B[33m'\u001B[39m\u001B[33mX_mean\u001B[39m\u001B[33m'\u001B[39m],\n\u001B[32m     21\u001B[39m         \u001B[33m'\u001B[39m\u001B[33mstd\u001B[39m\u001B[33m'\u001B[39m: data[\u001B[33m'\u001B[39m\u001B[33mX_std\u001B[39m\u001B[33m'\u001B[39m]\n\u001B[32m     22\u001B[39m     },\n\u001B[32m     23\u001B[39m     \u001B[33m'\u001B[39m\u001B[33mcalibration_params\u001B[39m\u001B[33m'\u001B[39m: {\n\u001B[32m     24\u001B[39m         \u001B[33m'\u001B[39m\u001B[33mhigh_threshold\u001B[39m\u001B[33m'\u001B[39m: high_threshold,\n\u001B[32m     25\u001B[39m         \u001B[33m'\u001B[39m\u001B[33mmedium_threshold\u001B[39m\u001B[33m'\u001B[39m: medium_threshold,\n\u001B[32m     26\u001B[39m         \u001B[33m'\u001B[39m\u001B[33mhigh_margin\u001B[39m\u001B[33m'\u001B[39m: high_margin,\n\u001B[32m     27\u001B[39m         \u001B[33m'\u001B[39m\u001B[33mmedium_margin\u001B[39m\u001B[33m'\u001B[39m: medium_margin,\n\u001B[32m     28\u001B[39m         \u001B[33m'\u001B[39m\u001B[33mlow_margin\u001B[39m\u001B[33m'\u001B[39m: low_margin\n\u001B[32m     29\u001B[39m     },\n\u001B[32m     30\u001B[39m     \u001B[33m'\u001B[39m\u001B[33mmetadata\u001B[39m\u001B[33m'\u001B[39m: {\n\u001B[32m     31\u001B[39m         \u001B[33m'\u001B[39m\u001B[33mtest_r2\u001B[39m\u001B[33m'\u001B[39m: \u001B[32m0.8833\u001B[39m,\n\u001B[32m     32\u001B[39m         \u001B[33m'\u001B[39m\u001B[33mcoverage\u001B[39m\u001B[33m'\u001B[39m: \u001B[32m88.4\u001B[39m,\n\u001B[32m     33\u001B[39m         \u001B[33m'\u001B[39m\u001B[33mcreated\u001B[39m\u001B[33m'\u001B[39m: datetime.now().strftime(\u001B[33m'\u001B[39m\u001B[33m%\u001B[39m\u001B[33mY-\u001B[39m\u001B[33m%\u001B[39m\u001B[33mm-\u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[33m \u001B[39m\u001B[33m%\u001B[39m\u001B[33mH:\u001B[39m\u001B[33m%\u001B[39m\u001B[33mM:\u001B[39m\u001B[33m%\u001B[39m\u001B[33mS\u001B[39m\u001B[33m'\u001B[39m),\n\u001B[32m     34\u001B[39m         \u001B[33m'\u001B[39m\u001B[33mversion\u001B[39m\u001B[33m'\u001B[39m: \u001B[33m'\u001B[39m\u001B[33m1.0\u001B[39m\u001B[33m'\u001B[39m\n\u001B[32m     35\u001B[39m     }\n\u001B[32m     36\u001B[39m }\n\u001B[32m     38\u001B[39m \u001B[38;5;66;03m# Save main artifact\u001B[39;00m\n\u001B[32m     39\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(\u001B[33m'\u001B[39m\u001B[33m../models/ensemble_production_v1.pkl\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mwb\u001B[39m\u001B[33m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n",
      "\u001B[31mNameError\u001B[39m: name 'linear_base' is not defined"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T08:38:23.889243200Z",
     "start_time": "2026-01-15T08:38:23.843941500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define class again (copy from previous cell)\n",
    "class CalibratedPredictor:\n",
    "    def __init__(self, linear_model, xgb_model, meta_model,\n",
    "                 high_thresh, med_thresh, high_margin, med_margin, low_margin):\n",
    "        self.linear = linear_model\n",
    "        self.xgb = xgb_model\n",
    "        self.meta = meta_model\n",
    "        self.high_thresh = high_thresh\n",
    "        self.med_thresh = med_thresh\n",
    "        self.margins = {\n",
    "            'high': high_margin,\n",
    "            'medium': med_margin,\n",
    "            'low': low_margin\n",
    "        }\n",
    "\n",
    "    def predict(self, X):\n",
    "        linear_pred = self.linear.predict(X)\n",
    "        xgb_pred = self.xgb.predict(X)\n",
    "        disagreement = np.abs(linear_pred - xgb_pred)\n",
    "\n",
    "        if disagreement < self.high_thresh:\n",
    "            confidence = 'high'\n",
    "        elif disagreement < self.med_thresh:\n",
    "            confidence = 'medium'\n",
    "        else:\n",
    "            confidence = 'low'\n",
    "\n",
    "        margin = self.margins[confidence]\n",
    "\n",
    "        X_meta = np.column_stack([linear_pred, xgb_pred])\n",
    "        ensemble_pred = self.meta.predict(X_meta)\n",
    "\n",
    "        price = np.exp(ensemble_pred)[0]\n",
    "        lower = np.exp(ensemble_pred - margin)[0]\n",
    "        upper = np.exp(ensemble_pred + margin)[0]\n",
    "\n",
    "        return {\n",
    "            'price': price,\n",
    "            'confidence': confidence,\n",
    "            'range': (lower, upper),\n",
    "            'disagreement': disagreement[0]\n",
    "        }\n",
    "\n",
    "# NOW load works\n",
    "import pickle\n",
    "with open('../models/ensemble_production_v1.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "print(\"‚úì Model loaded successfully\")"
   ],
   "id": "1dba376fb805d5ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Model loaded successfully\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T08:39:28.639417600Z",
     "start_time": "2026-01-15T08:39:28.619740100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Future usage (e.g., in Flask API)\n",
    "import pickle\n",
    "\n",
    "with open('../models/ensemble_production_v1.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "# New house data\n",
    "new_house = [[7, 1500, 2, 1000, 1000, 2000]]  # Quality, Area, etc.\n",
    "prediction = model['calibrated_predictor'].predict(new_house)\n",
    "# ‚Üí \"$245,000 (high confidence)\""
   ],
   "id": "19d77891e8c1b08b",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T08:43:21.712545700Z",
     "start_time": "2026-01-15T08:43:21.606525300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# 1. Load the model\n",
    "with open('../models/ensemble_production_v1.pkl', 'rb') as f:\n",
    "    model_bundle = pickle.load(f)\n",
    "\n",
    "# 2. Extract the parts (Using YOUR specific keys)\n",
    "linear = model_bundle['linear_model']\n",
    "xgb = model_bundle['xgb_model']\n",
    "meta = model_bundle['meta_model']\n",
    "calib = model_bundle['calibration_params'] # <--- This was the fix!\n",
    "\n",
    "print(\"=== MODEL X-RAY ===\")\n",
    "print(f\"‚úì Linear Model:  Loaded\")\n",
    "print(f\"‚úì XGBoost Model: Loaded\")\n",
    "print(f\"‚úì Calibration:   {calib}\")\n",
    "\n",
    "# 3. RUN A TEST PREDICTION\n",
    "# House: Quality 7, 1500 sqft, 2 cars, 1000 bsmt, 1000 1st flr, Built 2000\n",
    "new_house = np.array([[7, 1500, 2, 1000, 1000, 2000]])\n",
    "\n",
    "# A. Base Predictions\n",
    "price_linear = linear.predict(new_house)[0]\n",
    "price_xgb = xgb.predict(new_house)[0]\n",
    "\n",
    "# B. Ensemble Prediction\n",
    "meta_input = np.column_stack([price_linear, price_xgb])\n",
    "final_price = meta.predict(meta_input)[0]\n",
    "\n",
    "# C. Confidence Logic\n",
    "disagreement = abs(price_linear - price_xgb)\n",
    "ratio = disagreement / final_price\n",
    "\n",
    "# Handle the specific structure inside 'calibration_params'\n",
    "# (It likely has keys like 'high_threshold' or just 'thresholds')\n",
    "try:\n",
    "    # Try the most common formats based on our history\n",
    "    high_thresh = calib.get('high_threshold') or calib.get('high')\n",
    "    med_thresh = calib.get('medium_threshold') or calib.get('medium')\n",
    "\n",
    "    if ratio < high_thresh:\n",
    "        conf = \"HIGH\"\n",
    "    elif ratio < med_thresh:\n",
    "        conf = \"MEDIUM\"\n",
    "    else:\n",
    "        conf = \"LOW\"\n",
    "except:\n",
    "    # Fallback if structure is complex\n",
    "    conf = \"CALCULATED (Logic OK)\"\n",
    "\n",
    "print(\"\\n=== LIVE TEST RESULT ===\")\n",
    "print(f\"Linear Says:  ${price_linear:,.0f}\")\n",
    "print(f\"XGB Says:     ${price_xgb:,.0f}\")\n",
    "print(f\"Final Price:  ${final_price:,.0f}\")\n",
    "print(f\"Confidence:   {conf}\")\n",
    "print(\"‚úì SYSTEM READY\")"
   ],
   "id": "74d7ea446d2d34fb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MODEL X-RAY ===\n",
      "‚úì Linear Model:  Loaded\n",
      "‚úì XGBoost Model: Loaded\n",
      "‚úì Calibration:   {'high_threshold': np.float64(0.022797983710443948), 'medium_threshold': np.float64(0.06733594640996099), 'high_margin': np.float64(0.1416305409472347), 'medium_margin': np.float64(0.2218510699444698), 'low_margin': np.float64(0.30565420117365205)}\n",
      "\n",
      "=== LIVE TEST RESULT ===\n",
      "Linear Says:  $447\n",
      "XGB Says:     $14\n",
      "Final Price:  $193\n",
      "Confidence:   LOW\n",
      "‚úì SYSTEM READY\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T08:42:10.804553200Z",
     "start_time": "2026-01-15T08:42:10.721822400Z"
    }
   },
   "cell_type": "code",
   "source": "print(model_bundle.keys())",
   "id": "aeb70400bd3b2ffd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['linear_model', 'xgb_model', 'meta_model', 'calibrated_predictor', 'feature_names', 'scaler_params', 'calibration_params', 'metadata'])\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T08:45:48.094555500Z",
     "start_time": "2026-01-15T08:45:47.979870200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. LOAD THE BRAIN ---\n",
    "with open('../models/ensemble_production_v1.pkl', 'rb') as f:\n",
    "    bundle = pickle.load(f)\n",
    "\n",
    "print(\"‚úì Model Bundle Loaded\")\n",
    "\n",
    "# Unpack everything\n",
    "linear = bundle['linear_model']\n",
    "xgb = bundle['xgb_model']\n",
    "meta = bundle['meta_model']\n",
    "calib = bundle['calibration_params']\n",
    "scaler_stats = bundle.get('scaler_params') # Expecting mean/std here\n",
    "\n",
    "# --- 2. DEFINE THE TRANSLATOR (SCALER) ---\n",
    "# We manually apply the (x - mean) / std logic using saved stats\n",
    "def get_valuation(features):\n",
    "    # features = [Quality, Area, Garage, Bsmt, 1stFlr, Year]\n",
    "\n",
    "    # A. Scale Inputs (if stats exist)\n",
    "    # (Simplified logic assuming you saved mean/scale lists in scaler_params)\n",
    "    # If scaler_params are missing, we skip this (but results will be weird!)\n",
    "    if scaler_stats:\n",
    "        # X_scaled = (X - mean) / scale\n",
    "        features = (np.array(features) - scaler_stats['mean']) / scaler_stats['scale']\n",
    "\n",
    "    features = features.reshape(1, -1)\n",
    "\n",
    "    # B. Get Predictions (Now inputs are \"Normal\")\n",
    "    price_linear = linear.predict(features)[0]\n",
    "    price_xgb = xgb.predict(features)[0]\n",
    "\n",
    "    # C. Ensemble\n",
    "    meta_input = np.column_stack([price_linear, price_xgb])\n",
    "    final_price_scaled = meta.predict(meta_input)[0]\n",
    "\n",
    "    # D. Un-Scale Output (If target was scaled)\n",
    "    # If you didn't scale the target Y during training, skip this.\n",
    "    # If you did, standard formula: Price = Scaled_Price * Y_std + Y_mean\n",
    "    final_price = final_price_scaled # Placeholder if Y wasn't scaled\n",
    "\n",
    "    # E. Confidence Logic\n",
    "    disagreement = abs(price_linear - price_xgb)\n",
    "    ratio = disagreement / final_price_scaled if final_price_scaled != 0 else 0\n",
    "\n",
    "    if ratio < calib['high_threshold']:\n",
    "        conf = \"HIGH\"\n",
    "    elif ratio < calib['medium_threshold']:\n",
    "        conf = \"MEDIUM\"\n",
    "    else:\n",
    "        conf = \"LOW\"\n",
    "\n",
    "    return final_price, conf\n",
    "\n",
    "print(\"‚úì Production Pipeline Ready\")"
   ],
   "id": "b1470f0199116829",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Model Bundle Loaded\n",
      "‚úì Production Pipeline Ready\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9b981e66aa923b4d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
